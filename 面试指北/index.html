
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-7.0.3">
    
    
      
        <title>面试指北 - 个人笔记</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.1655a90d.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.7fa14f5b.min.css">
        
          
          
          <meta name="theme-color" content="#009485">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="teal" data-md-color-accent="pink">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#retinaface" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="个人笔记" class="md-header__button md-logo" aria-label="个人笔记">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            个人笔记
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              面试指北
            
          </span>
        </div>
      </div>
    </div>
    <div class="md-header__options">
      
    </div>
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    




<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="个人笔记" class="md-nav__button md-logo" aria-label="个人笔记">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    个人笔记
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      <label class="md-nav__link" for="__nav_1">
        一、计算机视觉专栏
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="一、计算机视觉专栏" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          一、计算机视觉专栏
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" class="md-nav__link">
        目标检测论文解读
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../OCR%E6%96%B9%E5%90%91%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" class="md-nav__link">
        OCR方向论文解读
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E4%BA%BA%E8%84%B8%E6%96%B9%E5%90%91%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" class="md-nav__link">
        人脸方向论文解读
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" class="md-nav__link">
        图像识别论文解读
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/" class="md-nav__link">
        深度学习基础
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      <label class="md-nav__link" for="__nav_2">
        二、AI代码专栏
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="二、AI代码专栏" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          二、AI代码专栏
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../PyTorch%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B/" class="md-nav__link">
        PyTorch快速教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../PaddlePaddle%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B/" class="md-nav__link">
        PaddlePaddle快速教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../caffe%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/" class="md-nav__link">
        Caffe快速教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../onnx%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/" class="md-nav__link">
        ONNX简明教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7%E4%BB%A3%E7%A0%81/" class="md-nav__link">
        深度学习工具代码
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../pandas%E3%80%81matplotlib%E7%AE%80%E6%B4%81%E7%AC%94%E8%AE%B0/" class="md-nav__link">
        PD+PLT简洁笔记
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      <label class="md-nav__link" for="__nav_3">
        三、常用工具专栏
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="三、常用工具专栏" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          三、常用工具专栏
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E9%87%8F%E5%8C%96%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/" class="md-nav__link">
        量化工具使用
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7%E6%95%99%E7%A8%8B/" class="md-nav__link">
        实用工具教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E7%BD%91%E7%AB%99%E6%94%B6%E9%9B%86/" class="md-nav__link">
        学习网站收集
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E5%BA%93%28albumentations%2BAugmentor%29/" class="md-nav__link">
        图像增强库
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      <label class="md-nav__link" for="__nav_4">
        四、编程语言专栏
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="四、编程语言专栏" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          四、编程语言专栏
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../c%2B%2B%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/" class="md-nav__link">
        c++简明教程
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../vim_cmake_git/" class="md-nav__link">
        vim_git_cmake
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../python%E5%88%B7%E9%A2%98/" class="md-nav__link">
        python刷题
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../java%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8Band%E5%AE%89%E5%8D%93%E5%BC%80%E5%8F%91/" class="md-nav__link">
        java简明教程and安卓开发
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#retinaface" class="md-nav__link">
    RetinaFace
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    注意力机制
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kmeans" class="md-nav__link">
    Kmeans聚类
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#focal-loss" class="md-nav__link">
    Focal Loss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#repulsion-lossrpln" class="md-nav__link">
    Repulsion Loss|[rɪ'pʌlʃən]:斥力
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tta" class="md-nav__link">
    TTA
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wbfweighted-boxes-fusioncode" class="md-nav__link">
    WBF(比赛专用:Weighted Boxes Fusion)code
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    数据增强
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#db1911-differentiable-binarization" class="md-nav__link">
    DB(19/11 Differentiable Binarization:可微分二值化)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mobilenet" class="md-nav__link">
    MobileNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#retinaface_1" class="md-nav__link">
    RetinaFace检测的局限性
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    模型剪枝
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    知识蒸馏(分类/回归用)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bwnbinary-weight-networks" class="md-nav__link">
    在线量化之二值化(BWN:Binary Weight Networks)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dbface" class="md-nav__link">
    人脸检测(DBFace:深蓝科技)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bn" class="md-nav__link">
    BN层融合
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#repvggbinary" class="md-nav__link">
    RepVGG(Binary无法使用)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#rotate-andrender" class="md-nav__link">
    Rotate-andRender人脸旋转增强
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#roc" class="md-nav__link">
    ROC曲线
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    人脸关键点和头部姿态
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    量化
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pact" class="md-nav__link">
    在线量化(PACT)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#msrcr" class="md-nav__link">
    MSRCR
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mmdetection" class="md-nav__link">
    mmdetection
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#detectorn2" class="md-nav__link">
    detectorn2
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>面试指北</h1>
                
                <p>猪只标注数据，有非猪只遮挡物的标全身，猪只相互遮挡的只标露出部分，露出极小部分的不标注，目的是为了<code>DB</code>网络的收敛。</p>
<h3 id="retinaface">RetinaFace<a class="headerlink" href="#retinaface" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>本身就是<code>RetinaNet</code>的改进版本，<code>resnet50-cabm的3个特征图--&gt;FPN(多尺度特征融合:3个特征图)-&gt;SSH(每个特征图都要进行SSH处理:3个特征图)--&gt;每个特征图都要通过通过两个1x1卷积分支来进行分类(是不是物体)和框回归(pre框与gt框的相对缩放量和位移量)</code>，<code>CBAM</code>的论文中说在<code>resnet50</code>中性能明显提高。</p>
</li>
<li>
<p><code>model</code>结构</p>
</li>
</ul>
<p><img alt="image-20210427104339060" src="../assets/image-20210427104339060.png" /></p>
<ul>
<li><strong>SSH(类似RPN操作)</strong>：<strong>通过简单的叠层卷积合并上下文信息(一般在two-stage 的目标检测模型当中，都是通过增大候选框的尺寸大小以合并得到更多的上下文信息)，速度更快，同时增加感受野</strong></li>
</ul>
<p><img alt="image-20210427135717540" src="../assets/image-20210427135717540.png" /></p>
<ul>
<li><strong>困难样例挖掘(hard negative mining)</strong>：<code>iou_thresh&gt;0.5</code>是正负样本的阈值，但是<code>negative &gt;&gt; positive</code>，结果会向负样本靠拢。保证正：负大约为<code>1:3</code>，正样本固定，首次负样本随机选取训练网络，，再用训练好的网络去预测负样本集中剩余的负样本，选择其中得分最高<code>topk</code>(<code>hard negative</code>)作为负样本集中重新训练，结果会越来越好.</li>
</ul>
<h3 id="_1">注意力机制<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h3>
<p>好处:稍微增加一点计算量但效果较好。</p>
<p><strong>SE模块</strong>:主要学习通道之间的相关性;通过对卷积的特征图进行**压缩**和**扩展**处理，得到一个和通道数一样的一维向量作为每个通道的评价分数，然后将该分数分别施加到对应的通道上，得到其结果。</p>
<ul>
<li>压缩:<code>CxHxW--&gt;global average pooling--&gt;1x1xC</code>这个<code>1x1xC</code>的特征图可以理解为全局感受野(线性的，如果直接乘没啥意义)</li>
<li>扩展:使用一个全连接神经网络，对<code>Sequeeze</code>之后的结果做一个**非线性变换**，得到各通道的评价分数。</li>
</ul>
<p><img alt="image-20210506165647024" src="../assets/image-20210506165647024.png" /></p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">SELayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channel</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SELayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">channel</span><span class="o">//</span><span class="n">reduction</span><span class="p">,</span><span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channel</span><span class="o">//</span><span class="n">reduction</span><span class="p">,</span><span class="n">channel</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="n">h</span><span class="p">,</span><span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">c</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div>
<p><strong>CBAM</strong>:集成了通道注意力模块和空间注意力模块，常在<code>ResNet</code>中的每个<code>block</code>中添加了<code>CBAM</code>模块，打比赛常用。</p>
<ul>
<li>通道注意力模块，<code>shared MLP:1x1conv+relu+1x1conv</code>，进行线性变换，<code>sigmoid</code>压缩得分到<code>[0,1]</code></li>
</ul>
<p><img alt="image-20210506172017739" src="../assets/image-20210506172017739.png" /></p>
<ul>
<li>空间注意力机制:</li>
</ul>
<p><img src="../assets/image-20210506172746349.png" alt="image-20210506172746349" style="zoom:80%;" /></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">avgout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 对通道维度求平均</span>
    <span class="n">maxout</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># 对通道维度求最大</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">avgout</span><span class="p">,</span> <span class="n">maxout</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 合并得到通道为2的卷积层</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="c1"># 进行卷积和sigmoid，得到通道为1的得分特征图</span>
    <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<ul>
<li>通道+空间注意力机制</li>
</ul>
<p><img src="../assets/image-20210506172718644.png" alt="image-20210506172718644" style="zoom:67%;" /></p>
<h3 id="kmeans">Kmeans聚类<a class="headerlink" href="#kmeans" title="Permanent link">&para;</a></h3>
<p>kmeans与kmeans++聚类:<a href="https://blog.csdn.net/zxyhhjs2017/article/details/83012425">博客</a></p>
<p><strong>kemeans聚类出k类长宽(不是长宽比)即可,由于数据集中图片大小可能不同，需要先归一化box的宽高:·=<code>w=w_box/w_img,h=h_box/h_img</code>，kmeans聚类的衡量指标是<code>d = 1 - IOU</code>(因为我们只关心pre_box与gt_box的iou，且iou越大表示距离越近)，计算IOU时，不用管box的位置，我们假设所有box的左上顶点都在原点</strong></p>
<p><img alt="image-20210427143646100" src="../assets/image-20210427143646100.png" /></p>
<ul>
<li><code>Kmeans</code>(缺点:对种子点的初始化非常敏感)</li>
<li>随机选取<code>K</code>个<code>box</code>作为初始<code>anchor</code>；</li>
<li>使用<code>1 - IOU</code>度量，将每个<code>box</code>分配给与其距离最近的<code>anchor</code>；</li>
<li>计算每个簇中所有<code>box</code>宽和高的均值，更新<code>anchor</code>；</li>
<li>重复2、3步，直到anchor不再变化，或者达到了最大迭代次数</li>
<li><code>kmeans++</code></li>
<li>随机选取<code>1</code>个<code>box</code>作为初始<code>anchor</code>；</li>
<li>使用<code>1 - IOU</code>度量，计算<code>box</code>与最近的聚类中心的距离D(x)；</li>
<li><code>选择D(x)</code>较大的点作为新增的聚类中心，注意不要选择最大值(排序按照概率值选择)，可能是异常点</li>
<li>重复2~3，直到k个聚类中心被选出来</li>
<li>利用这<code>k</code>个初始的聚类中心来运行标准的<code>k-means</code>算法</li>
</ul>
<h3 id="focal-loss">Focal Loss<a class="headerlink" href="#focal-loss" title="Permanent link">&para;</a></h3>
<p><img alt="image-20201202104032992" src="../assets/image-20201202104032992.png" /></p>
<p><img alt="image-20201202104447575" src="../assets/image-20201202104447575.png" /></p>
<p><code>Focal Loss</code>主要是在原有交叉熵损失的基础上加入了<code>gamma</code>因子和<code>alpha</code>因子，其中<code>gamma</code>因子主要是控制困难样本挖掘的，<code>alpha</code>因子主要是平衡正负样本比例不均衡的。</p>
<ul>
<li>困难样例挖掘，加入<code>gamma</code>因子</li>
</ul>
<p><img alt="image-20210510145945535" src="../assets/image-20210510145945535.png" /></p>
<ul>
<li>对于正样本而言，预测结果<code>y'=0.95</code>肯定是简单样本，<code>1-0.95</code>的<code>alpha</code>次方就很小，损失函数就很小;如果<code>y'=0.35</code>肯定是困难样本，<code>1-0.35</code>的<code>alpha</code>次方相对简单样本会较大，损失也会相对较大，这样就会更加关注困难样本。</li>
<li>
<p>对于负样本而言，预测结果<code>y'=0.05</code>肯定是简单样本，<code>0.05</code>的<code>alpha</code>次方就很小，损失函数就很小;如果<code>y'=0.75</code>肯定是困难样本，<code>0.75</code>的<code>alpha</code>次方相对简单样本会较大，损失也会相对较大，这样就会更加关注困难样本。</p>
</li>
<li>
<p>平衡正负样本比例不均衡，加入平衡因子<code>alpha</code></p>
</li>
</ul>
<p><img alt="image-20210510150156814" src="../assets/image-20210510150156814.png" /></p>
<ul>
<li><code>alpha=0.25</code>，通过控制平衡因子大小来平衡<code>loss</code></li>
</ul>
<h3 id="repulsion-lossrpln">Repulsion Loss|[rɪ'pʌlʃən]:斥力<a class="headerlink" href="#repulsion-lossrpln" title="Permanent link">&para;</a></h3>
<p>本文是旷视研究院CVPR2018上的一篇工作，主要目的是为了解决行人检测的遮挡。</p>
<p><strong>目标重叠导致两个问题：框偏移和漏检</strong></p>
<p><img src="../assets/image-20210428102702006.png" alt="image-20210428102702006" style="zoom: 80%;" /></p>
<p><strong>三部分:loss=P_T_loss+P远离B_loss+P远离P'_loss</strong>，<code>B</code>是除去本身要回归目标的真实框外，与其<code>IoU</code>最大的真实框;<code>P+</code>为正候选框集合，表示至少与其中一个真实框的<code>IoU</code>大于某个阈值(<code>0.5</code>)，其实就是正样本。</p>
<p><img alt="image-20210428111842634" src="../assets/image-20210428111842634.png" /></p>
<ul>
<li><strong>P,T吸引</strong>:<code>P_T_loss</code>：就是简单的<code>smoothL1 Loss</code>，用来优化预测框<code>P</code>和所负责的目标框<code>T</code>的距离。</li>
</ul>
<p><img alt="image-20210428112216770" src="../assets/image-20210428112216770.png" /></p>
<ul>
<li><strong>P,B排斥</strong>:<code>P远离B_loss</code>:<code>Smoothln(IoG(P,B))_loss</code>,使预测框<code>P</code>尽量远离和它重叠的第二大的<code>GT</code>框<code>B</code></li>
</ul>
<p><img src="../assets/image-20210428131315147.png" alt="image-20210428131315147"  /></p>
<ul>
<li><strong>P,P'排斥</strong>:<code>P远离P'_loss</code>，从代码上看，目的是保证使分派到不同<code>GT</code>的预测框之间尽量远离。</li>
</ul>
<p><img alt="image-20210428140129822" src="../assets/image-20210428140129822.png" /></p>
<ul>
<li><code>α和β</code>用于平衡两者的权重。</li>
</ul>
<h3 id="tta">TTA<a class="headerlink" href="#tta" title="Permanent link">&para;</a></h3>
<p><img alt="image-20210429113032725" src="../assets/image-20210429113032725.png" /></p>
<h3 id="wbfweighted-boxes-fusioncode"><strong>WBF(比赛专用:Weighted Boxes Fusion)</strong><a href="https://github.com/ZFTurbo/Weighted-Boxes-Fusion">code</a><a class="headerlink" href="#wbfweighted-boxes-fusioncode" title="Permanent link">&para;</a></h3>
<p><strong>加权边框融合</strong>，常用于融合多个模型对同一张图片的框预测，或者单个模型不同尺度的结果融合，比<code>NMS</code>慢<code>3</code>倍。</p>
<ul>
<li>
<p>每个模型的每个预测框都添加到<code>List B</code>，并将此列表按置信度得分<code>C</code>**降序**排列 </p>
</li>
<li>
<p>建立空<code>List L</code> 和 <code>list F</code>（用于融合的） </p>
</li>
<li>
<p>循环遍历<code>B</code>，并在<code>F</code>中找到与之匹配的<code>box</code>（同一类别<code>MIOU &gt; 0.55:最佳阈值</code>） </p>
</li>
<li>
<p>如果<code>step3</code> 中没有找到匹配的<code>box</code> 就将这个框加到<code>L</code>和<code>F</code>的尾部，如果 <code>step3</code> 中找到了匹配的<code>box</code> 就将这个框加到<code>L</code>，加入的位置是<code>box</code>在<code>F</code>中匹配框的<code>Index</code>；<code>L</code>中每个位置可能有多个框，需要根据这多个框更新对应<code>F[index]</code>的值，其实<code>list L</code>称为<code>dict L</code>更好。更新方式如下(对坐标值根据置信度求和):</p>
</li>
</ul>
<p><img alt="image-20210415144031690" src="../assets/image-20210415144031690.png" /></p>
<ul>
<li>遍历完成后对<code>F</code>中的元素再进行置信度得分的缩放，减少某些<code>box</code>只被少数模型预测到的置信值(如果群集中的多个框得分较低，则可能意味着 只有少数模型可以预测。 因此，我们需要降低此类情况的置信度得分)。</li>
</ul>
<p><img alt="image-20210415144436680" src="../assets/image-20210415144436680.png" /></p>
<h3 id="_2">数据增强<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p><strong>多尺度训练</strong>:<code>mmdetection</code>：</p>
<ul>
<li><code>keep_ratio=True</code>:<code>img_scale</code>的多尺度最多为两个。假设多尺度为<code>[(2000, 1200), (1333, 800)]</code>，则代表的含义为：首先将图像的短边固定到<code>800到1200</code>范围中的某一个数值假设为<code>1100</code>，那么对应的长边应该是短边的<code>ratio=1.5</code>倍，且长边的取值在<code>1333到2000</code>的范围之内。如果大于<code>2000</code>按照<code>2000</code>计算，小于<code>1300</code>按照<code>1300</code>计算。</li>
<li><code>keep_ratio=False</code>:<code>img_scale</code>的多尺度可以为任意多个。假设多尺度为<code>[(2000, 1200), (1666, 1000),(1333, 800)]</code>，则代表的含义为：随机从三个尺度中选取一个作为图像的尺寸进行训练。</li>
</ul>
<p><strong>Mixup</strong></p>
<ul>
<li><code>Mixup</code>:将随机的两张样本按比例混合，<code>loss</code>部分也根据混合比例分配；</li>
<li>两张样本图片:<code>inputs = lam*images + (1-lam)*images_random</code>，直接像素相加(尺寸不同时取最大值:<code>(600,800),(900,700)-&gt;(900,800)</code>,补<code>0</code>)。</li>
<li><code>loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)</code></li>
</ul>
<p><strong>MinIoURandomCrop</strong></p>
<ul>
<li>随机<code>crop the image &amp; bboxes</code>，由于可能正好把框切开但是必须保证有最小的<code>min iou thresh</code>,<code>min_ious=(0.1, 0.3, 0.5, 0.7, 0.9)</code>中随机选择。</li>
</ul>
<p><strong>其他</strong></p>
<ul>
<li><strong>Noise</strong>：椒盐噪声、高斯噪声、斑点噪声等随机选择</li>
<li><strong>Blur</strong>：高斯模糊，中值模糊等随机选择(推荐<code>mmdetection+ablur</code>)</li>
<li><strong>RandomBoxShake</strong>:随机原始的标注框抖动应对标注<code>noise</code></li>
<li><strong>PixelDistort[dɪ'stɔː&reg;t]使变形</strong>：像素级变换，一般都要加，其实就是调整图像的颜色，色调，饱和度</li>
</ul>
<h3 id="db1911-differentiable-binarization">DB(19/11 Differentiable Binarization:可微分二值化)<a class="headerlink" href="#db1911-differentiable-binarization" title="Permanent link">&para;</a></h3>
<p><a href="https://www.jianshu.com/p/efb23838264d">代码解析</a></p>
<p>直接语义分割，不用考虑遮挡问题；一般的语义分割网络都是直接输出二值语义概率图，然后通过阈值二值化得到最终结果(一般较好的结果需要复杂的后处理)，<code>DB</code>直接把<code>阈值二值化</code>过程变的**可微分**，直接进行网络优化，得到更好的语义概率图。</p>
<p><strong>标签制作</strong></p>
<p><img alt="image-20210429171046711" src="../assets/image-20210429171046711.png" /></p>
<ul>
<li>概率图<code>P</code>的生成：向里面压缩<code>d</code>，蓝框表示，<strong>黑色区域值为0，白色区域值为1</strong></li>
<li>阈值图<code>T</code>的生成：向外面扩展<code>d</code>成绿框，向里面压缩<code>d</code>成蓝框，绿蓝之间的为目标边界，值为绿蓝之间所有像素到红线(实际边界)的距离(<strong>收缩框和扩张框之间差集部分里每个像素点到原始图像边界的归一化距离[0,1]</strong>)，<strong>黑色区域值为<code>0+0.3</code>为了计算二值图时可以更好的分开边界。</strong></li>
</ul>
<p><strong>网络结构</strong></p>
<p><img alt="image-20210429161428773" src="../assets/image-20210429161428773.png" /></p>
<p><strong>可微分二值化</strong>:自适应阈值的可微分二值化不仅可以从背景中定位文本区域，还可以帮助区分开距离很近的文本实例。</p>
<p><img alt="image-20210429170223328" src="../assets/image-20210429170223328.png" /></p>
<p><strong>损失函数</strong>  </p>
<p><img alt="image-20210226164522915" src="../assets/image-20210226164522915.png" />  </p>
<ul>
<li><code>Ls,Lb</code>都是<code>binary cross-entropy (BCE:二元交叉熵)</code>,同时为了解决正负样本不均衡使用<code>hard negative mining</code>,使得正负样本<code>1:3</code>    </li>
</ul>
<p><img alt="image-20210226164841666" src="../assets/image-20210226164841666.png" /></p>
<ul>
<li><code>Lt</code>是预测结果和标签之间的<code>L1</code>距离，其中<code>Rd(红-&gt;绿)</code>是在膨胀<code>Gd</code>内像素的索引，<code>y*</code>是阈值<code>map</code>的标签，使用<code>10</code>是因为<code>Lt</code>的结果会影响到<code>Lb</code>(因为是同一个特征图的两个分支)。</li>
</ul>
<p><img alt="image-20210227133917063" src="../assets/image-20210227133917063.png" /></p>
<p><strong>推理流程</strong></p>
<p>在推理时可以采用概率图或近似二值图来生成文本框，为了方便作者选择了概率图，具体步骤如下:</p>
<ul>
<li>
<p>二值图确定:</p>
</li>
<li>
<p>使用**近似二值图B**，直接使用即可</p>
</li>
<li>
<p>使用**概率图P**：使用固定阈值<code>0.2</code>将概率图做二值化得到二值化图，由二值化图得到收缩文字区域(作者推荐)</p>
</li>
<li>
<p>将收缩文字区域按<code>Vatti clipping</code>算法(<code>PSENet</code>)的偏移系数<code>D'</code>进行扩张得到最终文本框</p>
</li>
</ul>
<p><img alt="image-20210429173332996" src="../assets/image-20210429173332996.png" /></p>
<h3 id="mobilenet">MobileNet<a class="headerlink" href="#mobilenet" title="Permanent link">&para;</a></h3>
<p><code>MobileNetV1</code> = 深度可分离卷积+<code>PReLU</code>(原始是<code>ReLU6</code>)+通道控制系数<code>widen_factor</code>=[<code>2</code>,<code>1</code>,<code>0.75</code>,<code>0.5</code>,<code>0.25</code>]，这样就产生模型<code>__all__ = ['mobilenet_2', 'mobilenet_1', 'mobilenet_075', 'mobilenet_05', 'mobilenet_025']</code></p>
<p>除了第一层卷积是普通卷积外，其他所有层都是深度可分离卷积(<code>group=in_channels conv + 1x1conv</code>)，激活函数全部使用<code>relu 或者prelu</code>，最后一层接<code>fc</code>之前使用<code>globalAvgPooling</code>，其实可以把<code>fc</code>换成<code>1x1 conv</code>来加快速度。</p>
<ul>
<li><code>mobilenetv1</code>主要是引入了**深度可分离卷积**</li>
</ul>
<p><img src="../assets/image-20210430093936926.png" alt="image-20210430093936926" style="zoom: 67%;" /></p>
<ul>
<li><code>mobilenetv2</code>主要是引入了**深度可分离卷积+倒残差结构**</li>
</ul>
<p><img src="../assets/image-20210518161542415.png" alt="image-20210518161542415" style="zoom:80%;" /></p>
<ul>
<li>
<p><code>mobilenetv3</code>主要是<code>MobileNet V1</code>的**深度可分离卷积**+<code>MobileNetV2</code>的**线性瓶颈的倒残差结构**+<strong><code>SE注意力模块</code></strong>，且结合采用神经网络搜索的方法，说是用了<code>h-swish=x*ReLU6(x+3)/6</code>函数(<strong>一般使用时常用relu代替</strong>)，同时对<code>v2</code>最后阶段做了更改:</p>
</li>
<li>
<p><code>mobilenetv1</code>最后使用的是<code>avgpool 7x7 +fc</code></p>
</li>
<li>
<p><code>mobilenetv2</code>最后使用的是<code>conv 1x1 + avgpool 7x7 + conv 1x1(==fc)</code></p>
<p><img src="../assets/image-20210518165817511.png" alt="image-20210518165817511" style="zoom:67%;" /></p>
<ul>
<li>先使用<code>conv1x1</code>卷积升维度，但由于此时的特征宽高是<code>7x7</code>的，引入了额外的计算量</li>
</ul>
</li>
<li>
<p><code>mobilenetv3</code>最后使用的是<code>conv 1x1 + avgpool 7x7 + conv 1x1 + conv 1x1(==fc)</code></p>
<p><img alt="image-20210518165934022" src="../assets/image-20210518165934022.png" /></p>
<ul>
<li>先进行<code>avgpool 7x7</code>，把特征宽高降为<code>1x1</code>，然后再是使用<code>1x1</code>卷积升维，计算量减少。</li>
</ul>
</li>
</ul>
<p><strong>PReLU:带参数的ReLU</strong></p>
<p><img alt="image-20210430095532598" src="../assets/image-20210430095532598.png" /></p>
<ul>
<li><code>ai=0</code>，那么<code>PReLU</code>退化为<code>ReLU</code>；</li>
<li>
<p>如果<code>ai</code>是一个很小的固定值(如<code>ai=0.01</code>)，则<code>PReLU</code>退化为<code>Leaky ReLU(LReLU)</code></p>
</li>
<li>
<p><code>BP</code>更新<code>ai</code>时，采用的是带动量的更新方式：下面两个系数分别是动量和学习率。</p>
</li>
</ul>
<p><img alt="image-20210430095751332" src="../assets/image-20210430095751332.png" /></p>
<h3 id="retinaface_1">RetinaFace检测的局限性<a class="headerlink" href="#retinaface_1" title="Permanent link">&para;</a></h3>
<ul>
<li>由于猪只尺寸相差不大，又是同一个方向运动，存在遮挡挤压状况，如果某个特征图产生的一个<code>anchor</code>框同时分配给这个目标，会产生目标重写现象，导致漏检(尤其是小特征图中，感受野较大，重写现象发生概率大)，<strong>增大图片分辨率或者增加特征图大小，速度会变慢</strong></li>
<li><code>kmeans</code>使得差不多尺寸的猪只(或者有几种特定尺度的物体)强制被分到不同层中被预测，这是有问题的。</li>
</ul>
<h3 id="_3">模型剪枝<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p><strong>gamma系数绝对值排序裁剪</strong></p>
<p><strong>系数训练方式</strong></p>
<p>剪枝后每层通道剩余设置为<code>2^x</code>数目，这样较稳定但牺牲了部分压缩率</p>
<ul>
<li>恒定<code>s</code>剪枝:一直以固定的<code>L1</code>惩罚系数<code>s=0.001</code></li>
<li>全局<code>s</code>衰减剪枝:<code>s = s if epoch &lt;= opt.epochs * 0.5 else s * 0.01</code>，超过<code>epochs/2</code>后惩罚系数衰减<code>100</code>倍，使得精度稍微恢复。</li>
<li>局部<code>s</code>衰减剪枝:超过<code>epochs/2</code>后对<code>85</code>%的通道(所有<code>bn</code>通道<code>s</code>排序)保持原始恒定惩罚系数<code>s</code>压缩，<code>15%</code>的通道进行<code>s</code>衰减<code>100</code>倍的压缩(<code>85%</code>是个先验知识，一般这个压缩率是最佳的)。</li>
</ul>
<p><strong>tensorboard记录稀疏BN层gamma权重变化</strong></p>
<p><img src="../assets/image-20210430105953844.png" alt="image-20210430105953844" style="zoom:80%;" /></p>
<p><strong>如何确定裁剪率</strong></p>
<p>设置裁剪率:<code>range(0.60,0.90,0.01)</code>，跑<code>mini_testData:100</code>张，确定最高<code>AP</code>的裁剪率<code>65.7%</code></p>
<p><strong>精度恢复</strong>:</p>
<ul>
<li><strong>微调finetune(3~5个epochs)</strong>，观察<code>finetune</code>前后<code>BN</code>层的权重分布</li>
</ul>
<p><img src="../assets/image-20210430111919599.png" alt="image-20210430111919599" style="zoom:80%;" /></p>
<ul>
<li>
<p>微调模型前后<code>Conv</code>等层权重变化平缓，但是<code>BN</code>层变化巨大，所以冻结其他层参数，只<code>finetune BN</code>层的参数，效果稍微有提升</p>
</li>
<li>
<p><strong>模型蒸馏(推荐)</strong>:对模型蒸馏来说，网络在结构相似的情况下提升效果尤为明显，剪枝模型和原始模型之间网络结果高度相似，使用蒸馏效果更好。</p>
</li>
</ul>
<h3 id="_4">知识蒸馏(分类/回归用)<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p><strong>只蒸馏一个输出层</strong></p>
<ul>
<li>
<p>要蒸馏的小模型，以大模型的输出的概率向量(<code>soft target</code>:<strong>软标签</strong>-&gt;拥有不同类之间关系的信息)为学习目标，因为<code>one-hot</code>包含的信息量很低<code>[0,1]</code>（类似<code>label smooth</code>），因为负标签也带有大量信息。</p>
</li>
<li>
<p>如何做，在训练的时候在<code>softmax</code>中增加温度参数<code>T</code>，推理的时候<code>T=1</code>，优化<code>L_soft</code>的时候常用<code>KL散度</code>计算<code>Loss</code>:<strong>交叉熵=<code>KL</code>散度+熵</strong>，<code>one-hot</code>标签的真实信息熵是固定的所以用交叉熵代替<code>KL</code>散度，但是<code>soft label</code>的信息熵是<code>teacher</code>网络生成的，不是固定的，所以必须用<code>KL</code>散度。</p>
</li>
</ul>
<p><img alt="image-20210210125249328" src="../assets/image-20210210125249328.png" /></p>
<p><img alt="image-20210210125715947" src="../assets/image-20210210125715947.png" /></p>
<ul>
<li>温度<code>T</code>:越小越放大正样本，越大越放大负样本(即放大小概率值分量所携带的信息)。</li>
</ul>
<p><img alt="image-20210210130121235" src="../assets/image-20210210130121235.png" /></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 损失函数</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">criterion2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">()</span>
<span class="c1"># 经典损失</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<span class="n">loss1</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="c1"># 蒸馏损失        </span>
<span class="n">teacher_outputs</span> <span class="o">=</span> <span class="n">teach_model</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">outputs_S</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">outputs</span><span class="o">/</span><span class="n">T</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">outputs_T</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">teacher_outputs</span><span class="o">/</span><span class="n">T</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">loss2</span> <span class="o">=</span> <span class="n">criterion2</span><span class="p">(</span><span class="n">outputs_S</span><span class="p">,</span><span class="n">outputs_T</span><span class="p">)</span><span class="o">*</span><span class="n">T</span><span class="o">*</span><span class="n">T</span>
<span class="c1">#综合损失结果</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss1</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">loss2</span><span class="o">*</span><span class="n">alpha</span>
</code></pre></div>
<p><strong>精度更高的模型蒸馏小模型提升点更少，原因分析</strong>：</p>
<p><img alt="image-20210210135323109" src="../assets/image-20210210135323109.png" /></p>
<ul>
<li><code>Teacher</code>更复杂，<code>Student</code>没有足够的能力来模仿<code>Teacher</code></li>
<li><code>Teacher</code>的精度更高，模型确定性更强，输出<code>logits</code>（<code>soft label</code>）变得<code>less soft</code>，趋近于<code>one-hot</code></li>
<li>解决方案:可以利用超大模型作为**助教网络**辅助蒸馏(超大网络作为<code>Teacher</code>,大网络作为<code>Teach-Assistant</code>，小网络作为<code>Student</code>)</li>
<li>首先对超大网络对大网络进行蒸馏(大网络的选取和超大网络相差不要太大(<code>7倍</code>以上)，不然也蒸不出来)</li>
<li>再用整理好的大网络对最终的小网络进行蒸馏</li>
</ul>
<p><strong>多个Teacher模型如何蒸馏<a href="https://mp.weixin.qq.com/s/l2O-0ZkYW3nFyAGaLS04aQ">link</a></strong></p>
<ul>
<li>将多个teacher模型的预测概率（softmax后输出）求平均值来进行蒸馏，效果好于随机选一个teacher模型进行蒸馏。</li>
</ul>
<p><img alt="image-20201214203900255" src="../assets/image-20201214203900255.png" /></p>
<p><strong>输出层和特征层一起蒸馏</strong></p>
<p><img alt="image-20210427162149923" src="../assets/image-20210427162149923.png" /></p>
<ul>
<li>对于T和S中间特征图输出维度不匹配的问题，采用在<code>S</code>网络输出接一个转换器(<code>conv+bn+mish</code>)，将其升维到<code>T</code>网络匹配，T的话直接接一个<code>mish</code>保证激活函数相同(<code>mish=x*tanh(ln(1+e^x))</code>)。<code>loss:nn.MSE--&gt;预测数据和原始数据对应点误差的平方和的均值</code></li>
</ul>
<p><img alt="image-20210210142154568" src="../assets/image-20210210142154568.png" /></p>
<p><strong>目标检测实际蒸馏</strong>(尝试三种)</p>
<ul>
<li><code>output</code>蒸馏:普通蒸馏<code>KL</code>散度</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 对于分类和回归都是按照KL散度loss直接进行蒸馏</span>
<span class="k">def</span> <span class="nf">distillation_loss1</span><span class="p">(</span><span class="n">output_s</span><span class="p">,</span> <span class="n">output_t</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">T</span> <span class="o">=</span> <span class="mf">3.0</span>
    <span class="n">Lambda_ST</span> <span class="o">=</span> <span class="mf">0.001</span>
    <span class="n">criterion_st</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">KLDivLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
    <span class="n">output_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">i</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">output_s</span><span class="p">])</span>
    <span class="n">output_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">i</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">+</span> <span class="mi">5</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">output_t</span><span class="p">])</span>
    <span class="n">loss_st</span>  <span class="o">=</span> <span class="n">criterion_st</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">output_s</span><span class="o">/</span><span class="n">T</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">output_t</span><span class="o">/</span><span class="n">T</span><span class="p">,</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">*</span> <span class="p">(</span><span class="n">T</span><span class="o">*</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">batch_size</span>
    <span class="k">return</span> <span class="n">loss_st</span> <span class="o">*</span> <span class="n">Lambda_ST</span>
</code></pre></div>
<ul>
<li><code>output</code>蒸馏:分类和回归分开蒸馏</li>
</ul>
<p>分类还是使用普通的蒸馏策略(<strong>使用KL散度loss来求分类总loss</strong>)，但对于回归<code>loss</code>,发现先对<code>student</code>+<code>target</code>的<code>boxs</code>求均值，然后优化<code>student</code>和<code>t_tar_mean_box</code>的<code>CIOU loss</code>(优于<code>1/2*l2 loss</code>)，效果更好，<code>alpha=0.001</code></p>
<ul>
<li>
<p><code>1/2*L2 loss</code>训练初期，<code>x</code>值很大时，其导数也很大，训练初期训练不稳定。但对于蒸馏来说，属于训练后期，类似<code>smooth l1 loss</code>的后期。</p>
</li>
<li>
<p>特征图蒸馏+<code>output</code>蒸馏</p>
</li>
</ul>
<p>因为网络结构一样，输出对应的中间四层特征图进行蒸馏，因为通道数的不同，使用<code>1x1 conv</code>保持维度相同，然后计算其<code>MSE loss</code>，使用较小的系数<code>0.005</code>加入到总<code>loss</code>里面。</p>
<ul>
<li>
<p><code>Teach-Assistant(助理) Distillation</code>:没有尝试</p>
</li>
<li>
<p>如果<code>T,S</code>之间差距非常大(<code>7</code>倍以上)，可以借助一个中间的网络<code>M</code>，先用<code>T</code>蒸馏<code>M</code>，再用<code>M</code>蒸馏<code>S</code></p>
</li>
</ul>
<h3 id="bwnbinary-weight-networks">在线量化之二值化(BWN:Binary Weight Networks)<a class="headerlink" href="#bwnbinary-weight-networks" title="Permanent link">&para;</a></h3>
<p><code>BWN</code>:论文中初次提出的权重二值化是把卷积或者全连接层的卷积核参数变成**<code>W_binary{-1,1}*α(尺度参数)</code>代替权重W_float32**，对于<code>activation</code>仍然采用<code>float32</code>全精度。</p>
<ul>
<li><code>W_binary = sign(W_float32)</code>，但是<code>sign</code>函数在<code>0</code>处不可导，<code>开山之作:BinaryNet</code>作者使用**<code>直通估计器:STE</code>**(前向提取输入的正负,即<code>{-1,+1}</code>，反向使用<code>clip(-1,x,1)的导数来拟合sign的导数</code>),也就是说<code>output_grad = abs(input)&gt;1---&gt;grad==0*src_grad</code>，当<code>output_grad = abs(input)&lt;=1---&gt;1*src_grad</code></li>
</ul>
<p><img alt="image-20210518195225762" src="../assets/image-20210518195225762.png" /></p>
<ul>
<li><code>α</code>如何确定最优？<code>α</code>最优值=<code>np.sum(abs(w)) / n</code>（该层相应卷积核参数的<code>L1</code>范数的均值），论文中有推理公式。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 如果要进行激活二值化，第一个卷积层参数不能是二值，因为图片是8bit，如果直接二值化，丢失信息过多</span>
<span class="c1"># STE</span>
<span class="k">class</span> <span class="nc">BinActive</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Binarize the input activations for ***** BNN and XNOR *****.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span> <span class="c1"># 使用y=x函数拟合梯度</span>
        <span class="k">return</span> <span class="nb">input</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="p">):</span>
        <span class="nb">input</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="n">grad_input</span> <span class="o">=</span> <span class="n">grad_output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="c1"># 开山之作BNN中激活值:当sign函数的输入的绝对值大于1的时候，将梯度置0可以得到更好的实验结果。</span>
        <span class="n">grad_input</span><span class="p">[</span><span class="nb">input</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">grad_input</span><span class="p">[</span><span class="nb">input</span><span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># 最终的梯度结果就是sign函数的梯度计算使用clip(-1,x,1)函数来拟合</span>
        <span class="k">return</span> <span class="n">grad_input</span> <span class="c1"># 当在[-1,1]范围内，直接返回</span>

<span class="k">class</span> <span class="nc">BWNConv2d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">bw</span> <span class="o">=</span> <span class="n">BinActive</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="c1"># 对权重进行二值化(量化)</span>
        <span class="n">bw</span> <span class="o">=</span> <span class="n">bw</span> <span class="o">*</span> <span class="n">alpha</span>
        <span class="c1"># bx = BinActive().apply(x) # 对激活值进行二值化(量化)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bw</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>
<p><strong>最终结果显示:每个卷积核自身的参数绝对值相同，但不同卷积核的绝对值不相同</strong></p>
<p><img alt="image-20210204200921876" src="../assets/image-20210204200921876.png" /></p>
<p><strong>DoReFa-Net在线量化任意比特(2,8等)</strong></p>
<p><strong>直通估计器STE</strong></p>
<p><img alt="image-20210519135241980" src="../assets/image-20210519135241980.png" /></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Function</span>
<span class="k">def</span> <span class="nf">quantize_k</span><span class="p">(</span><span class="n">r_i</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="n">k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">r_o</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">r_i</span> <span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
    <span class="k">return</span> <span class="n">r_o</span>

<span class="k">class</span> <span class="nc">DoReFaQuant</span><span class="p">(</span><span class="n">Function</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">r_i</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="n">tanh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">r_i</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">r_o</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">quantize_k</span><span class="p">(</span> <span class="n">tanh</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tanh</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="p">,</span> <span class="n">k</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">r_o</span> <span class="c1"># 返回的权重范围是[-1~1]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">dLdr_o</span><span class="p">):</span>
        <span class="c1"># due to STE, dr_o / d_r_i = 1 according to formula (5)</span>
        <span class="k">return</span> <span class="n">dLdr_o</span><span class="p">,</span> <span class="kc">None</span>

<span class="c1"># 改善版的对激活也做量化限定</span>
<span class="k">class</span> <span class="nc">ActivateQuantizer</span><span class="p">(</span><span class="n">Function</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">nbit</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">quantize_k</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span><span class="n">nbit</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">grad_output</span><span class="p">,</span> <span class="kc">None</span>    

<span class="k">class</span> <span class="nc">DorafaConv2d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span><span class="n">bitwidth</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">bw</span> <span class="o">=</span> <span class="n">DoReFaQuant</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">w</span><span class="p">,</span><span class="n">bitwidth</span><span class="p">)</span> <span class="c1"># 对权重进行Dorafa量化限定</span>
        <span class="c1"># 对x进行截断(x截断前先进行缩放（* 0.1），目的是减小截断误差)，适应于relu激活的函数，如果是使用PACT限定的话，就不能用了</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">ActivateQuantizer</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">bitwidth</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bw</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>
<h3 id="dbface">人脸检测(DBFace:深蓝科技)<a class="headerlink" href="#dbface" title="Permanent link">&para;</a></h3>
<p>优势:可以使用多尺度运算且无需计算<code>anchor</code>(耗时),</p>
<p><strong>数据输入</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 001.jpg #图片名</span>
x y w h lx1 ly1 lt1 lx2 ly2 lt2 ... <span class="c1"># box：x,y,w,h landmark:坐标(x1,y1),是否有效:t1</span>
x y w h lx1 ly1 lt1 lx2 ly2 lt2 ...
<span class="c1"># 002.jpg</span>
....
</code></pre></div>
<p><strong>需要注意的点</strong></p>
<ul>
<li>高斯热力图详解:可以理解为一个目标用一个高斯圆表示，目标框中心点值为<code>1</code>，如果<code>1</code>周围设置为<code>0</code>就太严格了，所以以该点为圆心，以和<code>GT</code>框<code>IOU</code>大于<code>0.7</code>的这些点(这些点生成的框也能很好的包围目标)为半径<code>r</code>，采用高斯函数生成最终的结果，<strong>如果有多个类某一个类的两个高斯分布发生了重叠，直接取元素间最大的就可以</strong></li>
</ul>
<p><img src="../assets/image-20210508163537746.png" alt="image-20210508163537746" style="zoom:80%;" /></p>
<ul>
<li>
<p><code>anchor base</code>的特性是目标越大正类loss贡献越大,<code>anchor free</code>的特性是所有目标都一个点，正类贡献无论大小都一样(一般对小目标较友好)，所以在多尺寸目标训练中，需要使用<code>pos_weights</code>来处理，增加大目标的权重。</p>
</li>
<li>
<p>具体做法:设置高斯权重热力图<code>heatmap_posweight</code>，在有大尺寸的目标图的点采用高斯分布圆，在计算损失的时候直接和<code>loss</code>相乘来增大大目标在损失中的权重占比。</p>
</li>
<li>
<p>对于<code>12*12</code>，低于这个分辨率的直接做了负样本做法是不合理的，合理的做法是忽略，不应该对<code>loss</code>产生贡献</p>
</li>
<li>
<p>具体做法是采用<code>keep_mask</code>图，低于<code>12*12</code>像素的点的坐标直接置为<code>0</code>，在计算<code>loss</code>的时候直接与<code>keep_mask</code>图相乘，即不参与损失贡献且对应的人脸关键点也不会参与计算损失值。</p>
</li>
<li>
<p>高斯热力图使用<code>Focal Loss</code>改版计算损失，默认<code>alpha=2,beta=4</code>，<strong>困难样例挖掘</strong></p>
</li>
</ul>
<p><img alt="image-20210510134701452" src="../assets/image-20210510134701452.png" /></p>
<ul>
<li>对于正样本而言，预测结果<code>y^=0.95</code>肯定是简单样本，<code>1-0.95</code>的<code>alpha</code>次方就很小，损失函数就很小;如果<code>y^=0.35</code>肯定是困难样本，<code>1-0.35</code>的<code>alpha</code>次方相对简单样本会较大，损失也会相对较大，这样就会更加关注困难样本。</li>
<li>对于负样本而言，预测结果<code>y^=0.05</code>肯定是简单样本，<code>0.05</code>的<code>alpha</code>次方就很小，损失函数就很小;如果<code>y^=0.75</code>肯定是困难样本，<code>0.75</code>的<code>alpha</code>次方相对简单样本会较大，损失也会相对较大，这样就会更加关注困难样本。</li>
<li>上面提到的困难样本指两个方面:<ul>
<li>真正困难样例，<code>Focal Loss</code>会增大这样样本对损失的贡献</li>
<li>样本分错情况，如果正负样本比例不均衡，也会出现更多的样本被分错，抑制这种分错样本。</li>
</ul>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">FocalLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">pos_weights</span><span class="p">,</span> <span class="n">keep_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">pos_inds</span> <span class="o">=</span> <span class="n">gt</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># 等于1 为正样本</span>
        <span class="n">neg_inds</span> <span class="o">=</span> <span class="n">gt</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="c1"># 小于1 为负样本</span>

        <span class="c1"># pos_weights:高斯权重图，负样本地方直接为0，正样本中间为1，半径r内高斯递减</span>
        <span class="n">pos_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pred</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="o">*</span> <span class="n">pos_weights</span>
        <span class="n">neg_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">gt</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">pred</span><span class="p">)</span> <span class="o">*</span> <span class="n">neg_inds</span>

        <span class="k">if</span> <span class="n">keep_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pos_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">pos_loss</span> <span class="o">*</span> <span class="n">keep_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">neg_loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">neg_loss</span> <span class="o">*</span> <span class="n">keep_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="c1"># 使用keep_mask图来忽略超小样本，不作为负样本loss</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pos_loss</span> <span class="o">=</span> <span class="n">pos_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">neg_loss</span> <span class="o">=</span> <span class="n">neg_loss</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">pos_loss</span> <span class="o">+</span> <span class="n">neg_loss</span><span class="p">)</span>
</code></pre></div>
<p><strong>网络结构</strong></p>
<p><img alt="image-20210507165035938" src="../assets/image-20210507165035938.png" /></p>
<p><img src="../assets/image-20210513153243096.png" alt="image-20210513153243096" style="zoom:80%;" /></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># 1.选取0,2,7 block + 进入block前的x(x=CBAModule(x))</span>
    <span class="n">s4</span><span class="p">,</span> <span class="n">s8</span><span class="p">,</span> <span class="n">s16</span><span class="p">,</span> <span class="n">s32</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">s32</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">s32</span><span class="p">)</span>

    <span class="c1"># 2.上采样采用的是双线性差值+conv+bn+relu，效果优于反卷积和最近邻。</span>
    <span class="n">s16</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up0</span><span class="p">(</span><span class="n">s32</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">connect2</span><span class="p">(</span><span class="n">s16</span><span class="p">)</span>
    <span class="n">s8</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up1</span><span class="p">(</span><span class="n">s16</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">connect1</span><span class="p">(</span><span class="n">s8</span><span class="p">)</span>
    <span class="n">s4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up2</span><span class="p">(</span><span class="n">s8</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">connect0</span><span class="p">(</span><span class="n">s4</span><span class="p">)</span>

    <span class="c1"># 3.使用SSH进行对融合后的特征图进行合并上下文信息 且 扩大感受野</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">detect</span><span class="p">(</span><span class="n">s4</span><span class="p">)</span> <span class="c1"># SSH</span>

    <span class="c1"># 4 高斯热力图，人脸框，landmark框都是在(H//4,W//4)的特征图上进行的,回到原图需要*4</span>
    <span class="c1"># 4.1 输出高斯热力图(N,1,H//4,W//4),sigmoid压缩到[0,1],使用FocalLoss计算损失，平衡正负样本比例，如果是多个类(N,class_nums,H//4,W//4)</span>
    <span class="n">heat_map</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># conv-&gt;out_channels=1,</span>
    <span class="n">heat_map</span> <span class="o">=</span> <span class="n">heat_map</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="c1"># hm使用sigmoid压缩范围[0,1]</span>

    <span class="c1"># 4.2 输出人脸框(N,4,H//4,W//4)tlrb:分别是距离框左上角和右下角的距离。GIoULoss优化(优于IOU,因为IOU无法优化两筐不重叠情况)，权重占比为5</span>
    <span class="n">box</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># conv-&gt;out_channels=4</span>
    <span class="n">box</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">box</span><span class="p">)</span> <span class="c1"># 进一步对框进行增强，目的是拉开其内元素的差距。</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_landmark</span><span class="p">:</span>
        <span class="c1"># 4.3 输出5个关键点(N,10,H//4,W//4),使用WingLoss计算损失，使得关键点更准确</span>
        <span class="n">landmark</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">landmark</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">heat_map</span><span class="p">,</span> <span class="n">box</span><span class="p">,</span> <span class="n">landmark</span>

    <span class="k">return</span> <span class="n">heat_map</span><span class="p">,</span> <span class="n">box</span>
</code></pre></div>
<p><strong>测试</strong></p>
<ul>
<li>高斯热力图:由一个<code>3x3 max pool(stride=1)</code>处理<code>heat_map</code>获得**高斯热点**(即最有可能为目标的中心坐标)，取<code>top1000</code>进行后处理。然后使用<code>thresh=0.3</code>来过滤掉高斯分值较低的点，找到高斯分值较高的中心点坐标(<code>cx,cy</code>)即可</li>
<li>人脸框输出值，根据高分的高斯热点中心点计算实际人脸坐标框，然后使用<code>nms</code>处理即可(<code>iou_thresh=0.3</code>)，网络输出的就是实际偏差值。</li>
<li>如果有<code>landmark</code>，和人脸坐标框相似，直接用<code>(cx,cy)+=xxx</code>来获取实际坐标值即可，网络输出的就是实际偏差值。</li>
</ul>
<p><strong>缺点</strong>：两个物体在GT中的中心点重叠了，就只能预测一个物体，因为只有一个中心点，但对于闸机/门禁/门锁等更加关注单人人脸，如果排队人背后有部分人脸检测不到才是最好的。</p>
<h3 id="bn">BN层融合<a class="headerlink" href="#bn" title="Permanent link">&para;</a></h3>
<p><strong>DBFace在使用量化工具量化时会进行BN+Conv的融合，融合公式如下</strong></p>
<p><img alt="image-20210510173102647" src="../assets/image-20210510173102647.png" /></p>
<h3 id="repvggbinary">RepVGG(Binary无法使用)<a class="headerlink" href="#repvggbinary" title="Permanent link">&para;</a></h3>
<p><strong>使用网络 Binary_Resnet18_0.25(channel/4,结尾fc),很多地方有<code>3x3</code>卷积，可用<code>repVGG</code>②增强,特征图缩小2倍可用<code>repVGG</code>①增强</strong>；人脸框扩充长边的<code>1.2</code>倍且短边补齐遇到边缘停止，切图若不是正方形短边对称补<code>127</code>到正方形状---&gt;<code>resize=(128,128)--center crop--&gt;(112,112)</code></p>
<p><img src="../assets/image-20210511130821822.png" alt="image-20210511130821822" style="zoom:80%;" /></p>
<p><img src="../assets/image-20210510204317347.png" alt="image-20210510204317347" style="zoom:67%;" /></p>
<ul>
<li>在训练时候使用<code>B</code>结构(<strong>这种结构有个弊端:经过卷积后特征图尺寸不能变化,所以可以用在不改变特征图大小的卷积上</strong>)，在推理时把每层的<code>3x3+1x1+x</code>进行融合，然后再进行推理</li>
</ul>
<p><strong>3x3卷积+1x1卷积+Identity融合</strong>:把<code>1x1,Identity</code>都变为<code>3x3</code>卷积后和<code>3x3</code>卷积的权重相加进行融合即可</p>
<ul>
<li>
<p><code>3x3卷积 p=1,s=1</code>这样特征图大小是没变的，<code>1x1卷积 p=0,s=1</code>特征图大小也是没有改变的，只需要把<code>1x1卷积padding一圈0变成3x3卷积核</code>，然后<code>return W_3x3+W_1x1_pad_3x3</code>即可</p>
</li>
<li>
<p><code>x-&gt;Identity-&gt;x</code>，如何变为<code>3x3</code>卷积呢?如果是深度可分离的<code>1x1</code>卷积，每个通道的值都为<code>1</code>，这样就能完成<code>Identity</code>效果,(<code>Depthwise卷积</code>不能融合普通卷积，就把<code>Depthwise卷积</code>改为普通卷积即可:第一个卷积核第一通道为<code>1</code>，其他通道为<code>0</code>);把<code>1x1卷积padding一圈0变成3x3卷积核</code>然后再和前两者<code>kernel</code>权重相加就可以了</p>
</li>
</ul>
<p><img src="../assets/image-20210511155012067.png" alt="image-20210511155012067" style="zoom:80%;" /></p>
<p><strong>补充:卷积过程</strong></p>
<ul>
<li>卷积计算公式:<code>w = (w + 2p -fw)/s + 1</code></li>
</ul>
<p><img src="../assets/image-20210510203808191.png" alt="image-20210510203808191" style="zoom: 67%;" /></p>
<h3 id="rotate-andrender">Rotate-andRender人脸旋转增强<a class="headerlink" href="#rotate-andrender" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>通用的人脸旋转一般是基于同一人脸的多视角数据训练直接生成新视角，但对图像质量要求高(受到图片质量以及数据分布的限制)；</p>
</li>
<li>
<p><strong>这个使用无监督训练:摆脱多视角数据，仅仅需要单张图片，利用三维人脸建模，通过反复的旋转和渲染操作构建自监督(渲染从任意角度旋转到当前角度的带遮挡伪影和瑕疵的人脸，从而和原图构建训练数据对)，然后用一个普通的<code>pix2pix</code>生成最终图像</strong>。注:三维空间到二维图像的额渲染是纹理注册的逆向过程</p>
</li>
</ul>
<p><img alt="image-20210511203822470" src="../assets/image-20210511203822470.png" /></p>
<ul>
<li><strong>Gan网络的生成</strong>:<code>CycleGAN</code>的<code>ResBlock</code>生成器，使用<code>pix2PixHD</code>的<code>loss</code>来训练鉴别器。</li>
</ul>
<p><img alt="image-20210511205249962" src="../assets/image-20210511205249962.png" /></p>
<ul>
<li>整体网络结构(<strong>角度[yaw,pitch]-&gt;[-90,90]</strong>)。</li>
</ul>
<p><img alt="image-20210511205557897" src="../assets/image-20210511205557897.png" /></p>
<h3 id="roc">ROC曲线<a class="headerlink" href="#roc" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>正类和负类:假设阈值为<code>0.6</code>,得分大于等于<code>0.6</code>的为正类，小于<code>0.6</code>的为负类</p>
</li>
<li>
<p><code>ROC</code>曲线的横纵坐标</p>
</li>
<li>
<p><strong>纵坐标<code>真阳率-TPR</code></strong>:预测为正实际为正占所有正实例的比例:<code>p=1,gt=1/all(gt=1)</code></p>
</li>
<li>
<p><strong>横坐标<code>假阳率-FPR</code></strong>:预测为正实际为负占所有负实例的比例:<code>p=1,gt=0/all(gt=0)</code></p>
</li>
<li>
<p><strong><code>真阴率-TNR=1-FPR</code></strong>:预测为负实际为负占所有负实例的比例:<code>p=0,gt=0/all(gt=0)</code></p>
</li>
<li>
<p>每个阈值代表一对<code>(FPR,TPR)</code>,阈值无穷大时预测无正例<code>FPR=TPR=0</code>，阈值为<code>0</code>时预测无负例<code>FPR=TPR=1</code>,一般随着阈值逐渐增大，正例越来越少，横坐标减少的更快</p>
</li>
</ul>
<p><img src="../assets/image-20210511171419879.png" alt="image-20210511171419879" style="zoom:67%;" /></p>
<ul>
<li>
<p>如何画<code>roc</code>曲线，一般选取<code>range(0.1,1,0.001)</code>共计<code>90</code>组阈值，计算<code>AUC:(Area under Curve)</code>，是个概率值<code>[0,1]</code>,越大分类效果越好。</p>
</li>
<li>
<p>为什么使用<code>ROC曲线</code>而不使用<code>PR</code>曲线？原因:<strong>当测试集中的正负样本的分布变换的时候(例如负样本数量增大10倍)，ROC曲线能够保持不变,但是PR曲线巨变</strong></p>
</li>
</ul>
<h3 id="_5">人脸关键点和头部姿态<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p><strong>backbone：MobileNetV1-0.5(avgpool+conv1x1 代替fc,fc效果稍微好点但速度慢),0.5指的是通道控制系数，最后一层使用<code>1x1</code>卷积代替<code>fc</code>，因为上层是全局平均池化层，10(关键点)+4(四元数)个值的回归，人脸检测<code>1.5</code>倍的扩框-遇到边缘停止-切图-对称补0到正方形-<code>rezie=(120,120)</code>搞定</strong></p>
<p><strong>使用的数据集</strong>:角度是弧度制,欧拉角都限定在<code>[-100度,100度]</code>，转为弧度范围是<code>[-1.75,1.75]</code>,由于**欧拉角和四元数(表示在一个四维空间的轨迹和方向，范围[-1,1])可以相互转换，直接回归四元数效果更好**</p>
<p><img alt="image-20210513104721816" src="../assets/image-20210513104721816.png" /></p>
<ul>
<li><code>300W-LP(large pose)</code>:由<code>300W(AFW,LFPW,HELEN,IBUG,XM2VTS等合集)</code>数据做的大型人脸姿态预测的一个综合数据库，里面包含<code>28</code>个<code>2d</code>关键点和头部姿态信息<code>[pitch,yaw,roll]</code>，共计<code>61225</code>张。</li>
</ul>
<p><img src="../assets/image-20210513143832016.png" alt="image-20210513143832016" style="zoom:80%;" /></p>
<ul>
<li><code>AFLW2000</code>:由<code>AFLW</code>数据库的前<code>2000</code>张图片及其三维信息组成，里面包含<code>21</code>个<code>2d</code>关键点和头部姿态信息<code>[pitch,yaw,roll]</code>，共计<code>2000</code>张。</li>
</ul>
<p><img src="../assets/image-20210512171118847.png" alt="image-20210512171118847" style="zoom:50%;" /></p>
<div class="highlight"><pre><span></span><code><span class="c1"># xxxx.jpg xxxx.mat</span>
<span class="c1"># mat文件具体包含以下内容：</span>
<span class="mi">1</span><span class="err">）</span><span class="n">pt2d</span><span class="err">：</span><span class="mi">21</span><span class="n">个二维点</span>
<span class="mi">2</span><span class="err">）</span><span class="n">Illum_Para</span><span class="err">：</span><span class="mi">1</span><span class="err">×</span><span class="mi">10</span> <span class="n">光照参数</span>
<span class="mi">3</span><span class="err">）</span><span class="n">Color_Para</span><span class="err">：</span><span class="mi">1</span><span class="err">×</span><span class="mi">7</span> <span class="n">颜色参数</span>
<span class="mi">4</span><span class="err">）</span><span class="n">Tex_Para</span><span class="err">：</span> <span class="mi">199</span><span class="err">×</span><span class="mi">1</span> <span class="n">纹理参数</span>
<span class="mi">5</span><span class="err">）</span><span class="n">Shape</span> <span class="n">Para</span><span class="err">：</span> <span class="mi">199</span><span class="err">×</span><span class="mi">1</span> <span class="n">形状参数</span>
<span class="mi">6</span><span class="err">）</span><span class="n">Exp_Para</span><span class="err">：</span> <span class="mi">29</span><span class="err">×</span><span class="mi">1</span> <span class="n">表情参数</span>
<span class="mi">7</span><span class="err">）</span><span class="n">Pose</span><span class="err">：</span> <span class="mi">1</span><span class="err">×</span><span class="mi">7</span> <span class="n">姿态参数</span><span class="err">，</span><span class="n">分别为</span><span class="err">：</span><span class="n">pitch</span><span class="err">，</span> <span class="n">yaw</span><span class="err">，</span> <span class="n">roll</span><span class="err">，</span> <span class="n">translation</span><span class="p">(</span><span class="n">dx</span><span class="err">，</span><span class="n">dy</span><span class="err">，</span><span class="n">dz</span><span class="p">)</span><span class="err">，</span><span class="n">scale</span>
<span class="mi">8</span><span class="err">）</span><span class="n">pt3d_68</span><span class="err">：</span> <span class="mi">3</span><span class="err">×</span><span class="mi">68</span> <span class="n">三维特征点</span>

<span class="kn">import</span> <span class="nn">scipy.io</span> <span class="k">as</span> <span class="nn">sio</span>
<span class="n">mat_dict</span> <span class="o">=</span> <span class="n">sio</span><span class="o">.</span><span class="n">loadmat</span><span class="p">(</span><span class="n">mat_path</span><span class="p">)</span>
<span class="n">mat_dict</span><span class="p">[</span><span class="s1">&#39;pt2d&#39;</span><span class="p">]</span> <span class="c1"># 获得的是原图的21个关键点</span>
<span class="n">mat_dict</span><span class="p">[</span><span class="s1">&#39;Pose&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">,:</span><span class="mi">3</span><span class="p">]</span> <span class="c1"># 获取pitch,yaw,roll 三个欧拉角，原始是弧度值</span>
</code></pre></div>
<p><strong>Wing Loss</strong></p>
<p>一般而言人脸关键点<code>loss</code>尝尝是<code>l2 loss</code>或者<code>smooth l2 loss</code>,但是尝尝因为**人脸姿态角度多样**而导致的检测精度不高，使用<code>wing loss</code>可以很好解决离群点(<code>large error</code>)问题和<code>small error</code>问题。</p>
<ul>
<li><code>L2 loss</code>或者<code>smooth l2 loss</code>在<code>0</code>附近(<code>small error</code>)的<code>gradient</code>变化趋于平缓的，更不容易优化；而且<code>L2 loss</code>很容易受离群点(<code>large error</code>)影响</li>
<li><code>wing loss</code>分段函数，当两点距离过远时，为了避免<code>loss</code>过大(<code>large loss</code>)使用<code>|x| - C</code>来限定<code>loss</code>不要过大；当<code>|x|&lt;w</code>时，<code>small error</code>时使<code>gradient</code>变化陡峭，使得模型可以继续优化。</li>
</ul>
<p><img alt="image-20210510154750642" src="../assets/image-20210510154750642.png" /></p>
<ul>
<li><code>wing</code>:翅膀，论文中没有解释命名为此的含义，但看<code>loss</code>像鸟的翅膀一样。</li>
</ul>
<p><strong>回归评价指标</strong></p>
<ul>
<li><strong>平均绝对值误差(MAE)</strong>，头部姿态:<code>3ddfa_AFLW2000@7.393_best3.83-&gt;6.42</code>；人脸关键点检测:<code>3ddfa_AFLW2000_21pts@8.250_best@4.70-&gt;5pts@2.385</code></li>
</ul>
<p><img alt="image-20210513144211547" src="../assets/image-20210513144211547.png" /></p>
<ul>
<li><strong>均方误差(MSE)</strong></li>
</ul>
<p><img alt="image-20210513144248349" src="../assets/image-20210513144248349.png" /></p>
<ul>
<li><strong>均方根误差(RMSE)</strong></li>
</ul>
<p><img alt="image-20210513144422801" src="../assets/image-20210513144422801.png" /></p>
<h3 id="_6">量化<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p><strong>fp32、fp16、int8</strong></p>
<ul>
<li>
<p><strong>编码存储方式不同</strong>：</p>
</li>
<li>
<p><code>FP32</code>占用<code>4</code>字节编码，共<code>32</code>位，其中<code>1</code>位为符号位，<code>8</code>为指数位，<code>23</code>为尾数位</p>
</li>
<li>
<p><code>FP16</code>占用<code>2</code>字节编码，共<code>16</code>位，其中<code>1</code>位为符号位，<code>5</code>为指数位，<code>10</code>为尾数位</p>
</li>
<li>
<p><code>int8</code>，八位整型占用<code>1</code>个字节，共<code>8</code>位</p>
</li>
<li>
<p>训练时为什么用<code>fp32</code>：<code>fp16</code>的值区间比<code>fp32</code>的值区间小很多，虽然训练很快，但<code>fp16</code>在计算过程中很容易出现**溢出错误:上溢出(&gt;65504)和下溢出(&lt;6x10^-8)**</p>
</li>
</ul>
<p><strong>TensorRT-int8量化(对称量化)</strong></p>
<ul>
<li>模型量化主要包括两个部分，一是针对权重<code>Weight</code>量化，一是针对激活值<code>Activation</code>量化，将权重和激活值量化到<code>8bit</code>用于等价<code>32bit</code>的性能</li>
</ul>
<p><img alt="image-20210513161423801" src="../assets/image-20210513161423801.png" /></p>
<ul>
<li>
<p><strong>使用量化校准集进行模型激活值分布的统计</strong>，确定激活层的量化参数的方式(每层都要统一多个样本)。</p>
</li>
<li>
<p>最简单的量化，一张归一化的图片<code>[0,1]-&gt;[0,255]</code>，其实就是系数的缩放。</p>
</li>
</ul>
<p><img alt="image-20210513161459561" src="../assets/image-20210513161459561.png" /></p>
<p><strong>如何选取最合适的scale factor值？</strong></p>
<ul>
<li>映射参数<code>-|max|-&gt;-127,|max|-&gt;127</code>，也就是把参数的绝对值最大值当做阈值；有个问题，当参数的分布不均匀时，有一部分是空缺的(例如:激活值全为正)；所以常**选择合适的阈值T,将<code>±|T| 映射为±127</code>,超出 阈值<code>±|T|</code> 外的直接加到截断区内最后一个值**</li>
</ul>
<p><img src="../assets/image-20210513162516266.png" alt="image-20210513162516266" style="zoom:80%;" /></p>
<ul>
<li>
<p>截断区(<code>-T~T</code>)之外的值为什么要加到截断区内最后一个值呢？(<strong>阈值还是那个阈值，就是计算的时候加到最后一值上就行，阈值是不改变的</strong>)</p>
</li>
<li>
<p>一是求<code>P</code>的概率分布时，需要总的<code>P</code>总值.</p>
</li>
<li>
<p>二将截断区之外的加到截断P的最后，这样是尽可能地将截断后的信息给加进来。</p>
</li>
<li>
<p>最优阈值<code>T</code>如何寻找？<strong>保证量化前后分布差异最小即可:KL散度(相对熵:用来衡量两个概率分布之间的差异)，所以使得KL散度最小即可(用来表示int8,fp32值分布之间的信息丢失程度)</strong>，这样就把问题转为求<code>int8</code>概率和<code>fp32</code>概率，然后用<code>KL散度作为指标</code>选取最优阈值<code>|T|</code>即可。</p>
</li>
</ul>
<p><img alt="image-20200813145451106" src="../assets/image-20200813145451106.png" /></p>
<ul>
<li>
<p><code>int8</code>是离散点，两值之间最小值是<code>1</code>，直接使用直方图<code>hist</code>来统计各个区间内有多少个点出现即可。例如<code>int8=[1,2,3,4,5] 在[1,1,4]区间出现1次，在[1.4,1.8]区间出现0次,...,在[4.6,5]出现1次，区间距离为0.4</code></p>
</li>
<li>
<p><code>fp32</code>，两值之间最小值是无穷小，那么如何选择<code>合适的区间距离</code>呢？由于要选择合适的阈值<code>T</code>，<code>NVIDAIA</code>推荐使用<code>2048</code>个<code>bins</code>，这样区间距离=<code>[max(x)-min(x)]/bins</code>，这样采用遍历<code>128bin-2047bin</code>来确定合适的阈值<code>T</code>(<code>bin</code>的中间值作为阈值)，使得速度不是特别慢，精度也会较高，<strong>注意常用min(abs(x))~max(abs(x))在此区间内进行2048bins</strong>。</p>
<ul>
<li>为什么不计算<code>0bin-127bin</code>？如果最佳阈值<code>T</code>在<code>[0bin,127bin]</code>那么超过<code>T</code>的值就直接截断，然后直接一一映射就好了但损失一定过大。</li>
</ul>
</li>
<li>
<p>返回一系列 <code>|T|</code>值，每一层都有一个 <code>|T|</code>。创建 <strong>CalibrationTable:[kælɪ'breɪʃ(ə)n]校准</strong>，然后把超过阈值<code>|T|</code>后的直接截断</p>
<p><img alt="image-20210513205129259" src="../assets/image-20210513205129259.png" /></p>
<p><img alt="image-20210514104449610" src="../assets/image-20210514104449610.png" /></p>
</li>
</ul>
<p><strong>插值</strong></p>
<ul>
<li>最近邻插值(新图坐标点填充附近临近点),对应坐标公式(原图<code>src</code>,新图<code>det</code>)<ul>
<li><code>src_x = det_x/det_w * src_x</code>;<code>src_y = det_y/det_h * srcy</code></li>
</ul>
</li>
<li>双线性插值(原图四点计算新图1点)，坐标点的寻找就按照最近邻即可。</li>
</ul>
<p><img alt="image-20210514134820552" src="../assets/image-20210514134820552.png" /></p>
<p><strong>pytorch的钩子函数</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 1.register_forward_hook，获取前向传播过程中，各个网络模块的输入和输出，可对输入和输出进行修改</span>
<span class="n">total_feat_out</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">total_feat_in</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">hook_fn_forward</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="nb">input</span><span class="p">,</span><span class="n">output</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model module:&quot;</span><span class="p">,</span><span class="n">m</span><span class="p">)</span>
    <span class="n">total_feat_out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="n">total_feat_in</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span><span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
    <span class="n">module</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">hook_fn_forward</span><span class="p">)</span> <span class="c1"># 这样会收集每个模块的输入和输出</span>


<span class="c1"># 2.register backward hook,获取神经网络反向传播过程中，操作各个模块输入端和输出端的梯度值</span>
<span class="n">total_grad_out</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">total_grad_in</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">def</span> <span class="nf">hook_fn_backward</span><span class="p">(</span><span class="n">m</span><span class="p">,</span><span class="n">grad_input</span><span class="p">,</span><span class="n">grad_output</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model module:&quot;</span><span class="p">,</span><span class="n">m</span><span class="p">)</span>
    <span class="n">total_grad_in</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_input</span><span class="p">)</span>
    <span class="n">total_grad_out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_output</span><span class="p">)</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span><span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
    <span class="n">module</span><span class="o">.</span><span class="n">register_backward_hook</span><span class="p">(</span><span class="n">hook_fn_backward</span><span class="p">)</span> <span class="c1"># 这样会收集每个模块的梯度输入和输出</span>

<span class="c1"># 3.pytorch自定义新层</span>
<span class="c1"># 3.1 继承 torch.nn.Module,实现__init__和forward函数即可</span>
<span class="c1"># 3.2 继承 torch.autograd.Function,实现__init__和forward函数还有backward，如果要自定义求导规则(例如二值化网络有些不可导函数)，就要用着个方法.</span>
<span class="k">class</span> <span class="nc">BinActive</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Binarize the input activations for ***** BNN and XNOR *****.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span> <span class="c1"># 使用y=x函数拟合梯度</span>
        <span class="k">return</span> <span class="nb">input</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">,</span> <span class="p">):</span>
        <span class="nb">input</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="n">grad_input</span> <span class="o">=</span> <span class="n">grad_output</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="c1"># 开山之作BNN中激活值:当sign函数的输入的绝对值大于1的时候，将梯度置0可以得到更好的实验结果。</span>
        <span class="n">grad_input</span><span class="p">[</span><span class="nb">input</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">grad_input</span><span class="p">[</span><span class="nb">input</span><span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># 最终的梯度结果就是sign函数的梯度计算使用clip(-1,x,1)函数来拟合</span>
        <span class="k">return</span> <span class="n">grad_input</span>
<span class="c1"># 3.1 应用</span>
<span class="k">class</span> <span class="nc">BWNConv2d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BWNConv2d</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span><span class="n">dilation</span><span class="p">,</span><span class="n">groups</span><span class="p">,</span><span class="n">bias</span><span class="p">,</span><span class="n">padding_mode</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">w</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">bw</span> <span class="o">=</span> <span class="n">BinActive</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="c1"># 直接把权重弄成[-1,1],当然torch.nn.Module也可以实现，但是求导方式就按照默认求导方式走了。</span>
        <span class="n">bw</span> <span class="o">=</span> <span class="n">bw</span> <span class="o">*</span> <span class="n">alpha</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bw</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>
</code></pre></div>
<h3 id="pact">在线量化(PACT)<a class="headerlink" href="#pact" title="Permanent link">&para;</a></h3>
<p>模型量化主要包括两个部分，一是对权重Weight量化，一是针对激活值Activation量化。同时对两部分进行量化，才能获得最大的计算效率收益。权重可以借助网络正则化等手段，让权重分布尽量紧凑，减少离群点、不均匀分布情况发生，而对于激活值还缺乏有效的手段，而且离线量化时，无论是对称量化还是非对称量化，都会受到**离群点、float参数分布不均匀的影响**，造成量化损失增加。</p>
<p><code>PACT:parameterized clipping activation</code>详解:<strong>通过在量化激活值之前去掉一些离群点</strong>，将模型量化带来的精度损失降到最低，甚至比原模型准确率更高。</p>
<ul>
<li>作者发现，在量化时激活值的量化结果和全精度结果相差较大，分析原因发现：相较于<code>weight</code>基本在<code>0到1</code>范围内，<code>activation</code>的值的范围是无限大的，这是<code>RELU</code>的结果；所以提出**截断式RELU**的激活函数。该截断的上界，即<code>α</code>是可学习的参数，这保证了每层能够通过训练学习到不一样的量化范围，最大程度降低量化带来的舍入误差（这样使得模型，不断裁剪激活值范围，使得激活值分布收窄，从而降低量化映射损失）。</li>
<li>其实就是用<code>PACT</code>函数代替<code>ReLU</code>函数即可。</li>
</ul>
<p><img src="../assets/image-20210518144130663.png" alt="image-20210518144130663" style="zoom:80%;" /></p>
<ul>
<li><code>PaddleSlim</code>改进版——PACT量化实现:但是在实际使用中，将要进行量化的激活值不一定来自<code>ReLU</code>激活函数</li>
</ul>
<p><img src="../assets/image-20210518144525677.png" alt="image-20210518144525677" style="zoom:80%;" /></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">paddle</span>
<span class="k">class</span> <span class="nc">PACT</span><span class="p">(</span><span class="n">paddle</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PACT</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">alpha_attr</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">ParamAttr</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">full_name</span><span class="p">()</span> <span class="o">+</span> <span class="s2">&quot;.pact&quot;</span><span class="p">,</span>
            <span class="n">initializer</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">initializer</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1000.0</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_parameter</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">attr</span><span class="o">=</span><span class="n">alpha_attr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out_left</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
        <span class="n">out_right</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">out_left</span> <span class="o">+</span> <span class="n">out_right</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div>
<p><strong>人脸检测-backbone:mobilenetv3量化损失过大</strong></p>
<p><code>DBFace</code>使用在线量化的形式，卷积使用<code>BWN</code>二值化量化(<code>DorafaNet</code>的目的是把卷积参数限定在适合<code>k_bit</code>量化的<code>[-1,1]</code>之间的数，和二值化参数的目标重叠了)，<code>relu</code>改为<code>PACT</code>即可，进行<code>int8</code>量化的时候也简单(类似<code>relu6</code>):<code>float:conv1-&gt;relu6-&gt;conv1</code>;前向统计量化系数<code>conv1_int8-&gt;s1,conv2_int8-&gt;s2</code>;<code>conv1_int8*s1=conv1_float---&gt;relu6---&gt;conv2_int8*s2=conv2_float</code>，原理就是**反量化-&gt;relu6-&gt;量化**，其实是可以合并的<code>clip(clip(conv1_int8*s1,0,6)/s2,0,255)</code>，<strong>注意:卷积中并没有<code>clip</code>层</strong>。</p>
<ul>
<li><code>MobileNetV3</code>，作为<code>MobileNet</code>系列模型的集大成者,结合了<code>MobileNet V1</code>的**深度可分离卷积**+<code>MobileNetV2</code>的**线性瓶颈的倒残差结构**+<strong><code>SE注意力模块</code></strong>，且结合采用神经网络搜索的方法。但此模型对离线量化或在线量化极为敏感，带来的精度损失都很大，几乎达到了不可用的程度。但使用 <code>PACT</code>可以很好的解决该问题</li>
</ul>
<p><img alt="image-20210518145206235" src="../assets/image-20210518145206235.png" /></p>
<p><img alt="image-20210518125627524" src="../assets/image-20210518125627524.png" /></p>
<h3 id="msrcr">MSRCR<a class="headerlink" href="#msrcr" title="Permanent link">&para;</a></h3>
<p><strong>SSR(Single Scale Retinex)</strong></p>
<p><img alt="image-20210517102510487" src="../assets/image-20210517102510487.png" /></p>
<ul>
<li><code>I(x,y)</code>代表被观察或照相机接收到的图像信号(<strong>暗图</strong>)；</li>
<li><code>L(x,y)</code>代表环境光的照射分量(<strong>通过对原始图像进行高斯模糊/均值模糊得到</strong>) ;</li>
<li><code>R(x,y)</code>表示携带图像细节信息的目标物体的反射分量 (<strong>增强图</strong>)。</li>
<li><code>Log[R(x,y)]</code>量化为<code>0到255</code>范围的像素值，作为最终的输出<code>R(x,y) = ( Value - Min ) / (Max - Min) * (255-0)</code></li>
</ul>
<p><strong>MSR(Multi-Scale Retinex)</strong></p>
<p>论文中说上面高斯模糊时，尺度取值较小时， 能够较好地完成动态范围的压缩，暗区域的细节能得到较好地增强，但输出颜色易失真；取值较大时，色感一致性较好，所以一般取三个尺度来进行多尺度。</p>
<ul>
<li>需要对原始图像进行每个尺度的高斯模糊，得到模糊后的图像<code>Li(x,y)</code>,其中小标i表示尺度数.</li>
<li><code>Log[R(x,y)] = Weight(i)* ( Log[Ii(x,y)]-Log[Li(x,y)]);</code></li>
<li>其中<code>Weight(i)</code>表示每个尺度对应的权重，要求各尺度权重之和必须为<code>1</code>，经典的取值为等权重。</li>
<li><code>SSR</code>和<code>MSR</code>普遍都存在的问题：存在明显的偏色效果</li>
</ul>
<p><strong>MSRCR(带色彩恢复的多尺度视网膜增强算法)</strong></p>
<ul>
<li>主要是引入了均值和方差的概念，分别计算出 <code>Log[R(x,y)]</code>中<code>R/G/B</code>各通道数据的均值<code>Mean</code>和均方差<code>Var</code>（注意是均方差）</li>
<li>利用类似下述公式计算各通道的<code>Min和Max</code>值，<code>Dynamic=2</code>时效果较好：</li>
<li><code>Min = Mean - Dynamic * Var;</code></li>
<li><code>Max = Mean + Dynamic * Var;</code></li>
<li>对<code>Log[R(x,y)]</code>的每一个值<code>Value</code>，进行线性映射:</li>
<li><code>R(x,y) = ( Value - Min ) / (Max - Min) * (255-0)</code>，注意溢出时要截断。</li>
</ul>
<h3 id="mmdetection">mmdetection<a class="headerlink" href="#mmdetection" title="Permanent link">&para;</a></h3>
<p>支持<code>Rcnn系列、SSD系列、YOLOV3/YOLACT/YOLOF、AnchorFree系列、transform系列</code>,支持混合精度训练、各种常见的<code>backbone</code>、各种常见组件<code>loss:IOU系列、多种BN</code></p>
<p><strong>自定义数据集的训练、测试</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 1.将数据集做成voc/coco等格式(内含有覆盖代码to_coco/_voc.py)，按照其要求放置即可；或者可以自定义类，放在mmdet/datasets/my_dataset.py,然后再cfg文件中type=&#39;MyDataset&#39;,ann_file=/path/ 进行指定即可</span>
<span class="nd">@DATASETS</span><span class="o">.</span><span class="n">register_module</span><span class="p">()</span> <span class="c1"># 现在DATASETS中进行注册</span>
<span class="n">MyDataset</span><span class="p">(</span><span class="n">CustomDataset</span><span class="p">):</span> <span class="c1"># 实现 两个方法,load_annotations+get_ann_info</span>

<span class="c1"># 2.选择合适的配置文件进行配置(py配置:数据增强方式、loss函数，优化器等;数据类别(名称、数目)、数据type(coco/voc)、数据路径、预训练权重等)</span>

<span class="c1"># 3.训练可以单/多gpu，默认每个epoch都验证一次(map),可以在cfg里设置(例:每隔5个epoch验证)</span>

<span class="c1"># 4.测试,mmdet有高层API调用，只需要加载cfg+.pth，然后执行前向推理并显示结果，只需要几行代码就可以完成；当然也支持异步推理.如果要在标准数据数据集上测试(coco/voc)，也提供了测试代码(single image:默认 or batched images，单/多gpu测试)，只需要修改参数即可。</span>
</code></pre></div>
<p><strong>配置文件中的重要选项</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 1.model:type=&#39;faster_rcnn&#39;/&#39;mask_rcnn&#39; # 选择合适的检测器</span>
<span class="c1"># 2.backbone:&#39;resnet-50/resnetxt-101&#39; # 选择网络结构</span>
<span class="c1"># 3.neck:`fpn/pafpn/nasfpn/c4` # 选择合适的neck</span>
<span class="c1"># 4.norm_setting:`bn/gn/syncbn/` # 选择合适的bn</span>
<span class="c1"># 5.misc:`dconv/attention` # 为模型选择其他插件</span>
<span class="c1"># 6.loss_cls/loss_bbox:`CrossEntropyLoss、FocalLoss `/`IoU Losses、L1 losses`</span>
<span class="c1"># dataset_cfg</span>
</code></pre></div>
<p><strong>一些自定义配置</strong></p>
<div class="highlight"><pre><span></span><code><span class="c1"># 1.自定义数据类，放在mmdet/datasets/my_dataset.py,然后再cfg文件中type=&#39;MyDataset&#39;,ann_file=/path/ 进行指定即可</span>
<span class="kn">from</span> <span class="nn">.builder</span> <span class="kn">import</span> <span class="n">DATASETS</span>
<span class="kn">from</span> <span class="nn">.custom</span> <span class="kn">import</span> <span class="n">CustomDataset</span>
<span class="nd">@DATASETS</span><span class="o">.</span><span class="n">register_module</span><span class="p">()</span> <span class="c1"># 现在DATASETS中进行注册</span>
<span class="n">MyDataset</span><span class="p">(</span><span class="n">CustomDataset</span><span class="p">):</span> <span class="c1"># 实现 两个方法,load_annotations+get_ann_info</span>


<span class="c1"># 2.自定义模型类：</span>
<span class="c1"># 2.1 更换backbone: mmdet/models/backbones/mobilenet.py # 自定义模型结构</span>
<span class="kn">from</span> <span class="nn">..builder</span> <span class="kn">import</span> <span class="n">BACKBONES</span>
<span class="nd">@BACKBONES</span><span class="o">.</span><span class="n">register_module</span><span class="p">()</span> <span class="c1"># 注册</span>
<span class="k">class</span> <span class="nc">MobileNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="c1"># 在mmdet/models/backbones/__init__.py中导入</span>
<span class="kn">from</span> <span class="nn">.mobilenet</span> <span class="kn">import</span> <span class="n">MobileNet</span>
<span class="c1"># 2.1.1 cfg使用</span>
<span class="n">model</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="o">...</span>
    <span class="n">backbone</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;MobileNet&#39;</span><span class="p">,</span><span class="n">arg1</span><span class="o">=</span><span class="n">xxx</span><span class="p">,</span><span class="n">arg2</span><span class="o">=</span><span class="n">xxx</span><span class="p">),</span>
    <span class="o">...</span>
<span class="c1"># 2.2 更换neck: mmdet/models/necks/pafpn.py # 自定义neck</span>
<span class="kn">from</span> <span class="nn">..builder</span> <span class="kn">import</span> <span class="n">NECKS</span>  
<span class="nd">@NECKS</span><span class="o">.</span><span class="n">register_module</span><span class="p">()</span> <span class="c1"># 注册</span>
<span class="k">class</span> <span class="nc">PAFPN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span><span class="c1">#自定义neck类，cfg中type=&#39;类名&#39;即可</span>
<span class="c1"># 在mmdet/models/necks/__init__.py导入</span>
<span class="kn">from</span> <span class="nn">.pafpn</span> <span class="kn">import</span> <span class="n">PAFPN</span>
<span class="c1"># 2.2.1 cfg中使用</span>
<span class="n">neck</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;PAFPN&#39;</span><span class="p">,</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="p">[</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">],</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="n">num_outs</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="o">....</span>


<span class="c1"># 3.自定义loss mmdet/models/losses/xxx_loss.py</span>
<span class="kn">from</span> <span class="nn">..builder</span> <span class="kn">import</span> <span class="n">LOSSES</span>
<span class="nd">@LOSSES</span><span class="o">.</span><span class="n">register_module</span><span class="p">()</span> <span class="c1"># 注册</span>
<span class="k">class</span> <span class="nc">FocalLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span> <span class="c1"># 自定义loss类，cfg中type=&#39;类名&#39;即可</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">use_sigmoid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">gamma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                 <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
                 <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                 <span class="n">loss_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
<span class="c1"># 在mmdet/models/losses/__init__.py导入</span>
<span class="kn">from</span> <span class="nn">.focal_loss</span> <span class="kn">import</span> <span class="n">FocalLoss</span>
<span class="c1"># 3.1 在cfg中使用</span>
<span class="n">loss_cls</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
    <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;FocalLoss&#39;</span><span class="p">,</span>
    <span class="n">use_sigmoid</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
    <span class="n">loss_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</code></pre></div>
<p><strong>其他工具</strong></p>
<ul>
<li><code>log</code>分析:画出<code>loss_cls、loss_bbox</code>的<code>loss/mAP</code>图，<code>tools/analysis_tools/analyze_logs.py</code></li>
<li>结果分析:存储高得分<code>topk(50)</code>或者低的分<code>score-thr&lt;0.3</code>的图片到<code>result</code>进行分析</li>
</ul>
<h3 id="detectorn2">detectorn2<a class="headerlink" href="#detectorn2" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>该框架目前内置的模型多是**双阶段检测器**(<code>Faster-Rcnn,,RetinaNet(ssd+focalLoss)</code>)</p>
</li>
<li>
<p>自定义数据集训练</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 1.准备数据集，转为coco格式后按照dataset/readme.md要求摆好数据，然后再detectron.data.datasets里按格式进行注册数据集，当然也可以自定义函数来处理，麻烦。</span>
<span class="c1"># 2.按照要求写训练cfg，很重要:多尺度训练尺寸，类别，设置迭代次数、学习率衰减等。</span>
<span class="c1"># 3.直接使用tool/train_net.py训练即可，里面是使用detectron2.engine.DefaultTrainer(cfg).train()进行训练即可，也可以使用tensorboard开启可视化</span>
<span class="c1"># 4.使用detectron2.evaluation.COCOEvaluator 评测数据集的map即可(含有tta测试)</span>
</code></pre></div>
<ul>
<li>数据增强</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">transforms</span> <span class="k">as</span> <span class="n">T</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">AugInput</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">boxes</span><span class="o">=</span><span class="n">boxes</span><span class="p">,</span> <span class="n">sem_seg</span><span class="o">=</span><span class="n">sem_seg</span><span class="p">)</span> <span class="c1"># # 定义数据增强的输入（必须输入图片，其它输入可选）。</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">AugmentationList</span><span class="p">([</span>
    <span class="n">T</span><span class="o">.</span><span class="n">RandomBrightness</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">),</span>
    <span class="n">T</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(</span><span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">T</span><span class="o">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="s2">&quot;absolute&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">))</span>
<span class="p">])(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># 2.继承T.Augmentation定义新的数据增强</span>
<span class="k">class</span> <span class="nc">MyColorAugmentation</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">Augmentation</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">get_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">T</span><span class="o">.</span><span class="n">ColorTransform</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>写自己的模型:更换<code>backbone</code>或者<code>box head</code>，使用其注册机制，注册后直接在<code>config</code>调用即可</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 1. 使用自己定义的BackBone</span>
<span class="kn">from</span> <span class="nn">detectron2.modeling</span> <span class="kn">import</span> <span class="n">BACKBONE_REGISTRY</span><span class="p">,</span> <span class="n">Backbone</span><span class="p">,</span> <span class="n">ShapeSpec</span>
<span class="nd">@BACKBONE_REGISTRY</span><span class="o">.</span><span class="n">register</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">ToyBackbone</span><span class="p">(</span><span class="n">Backbone</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># 创建你自己的 backbone:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;conv1&quot;</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">image</span><span class="p">)}</span>

    <span class="k">def</span> <span class="nf">output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;conv1&quot;</span><span class="p">:</span><span class="n">ShapeSpec</span><span class="p">(</span><span class="n">channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span><span class="n">stride</span><span class="o">=</span><span class="mi">16</span><span class="p">)}</span>

<span class="c1"># 2.config配置</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># 读取 config</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">BACKBONE</span><span class="o">.</span><span class="n">NAME</span> <span class="o">=</span> <span class="s1">&#39;ToyBackbone&#39;</span> <span class="c1"># 或者你可以在 config file 中更改</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
</code></pre></div>
<ul>
<li>推理</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="c1"># 1.加载推理配置文件，里面主要有模型路径，测试集路径，测试的指标，测试图片size等，将配置文件加载到 DefaultPredictor对象里 并 进行推理</span>
<span class="n">predictor</span> <span class="o">=</span> <span class="n">DefaultPredictor</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="c1"># 2.使用Visualizer类来可视化输出结果</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">im</span><span class="p">[:,:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">MetadataCatalog</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">DATASETS</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">draw_instance_predictions</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">&#39;instances&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span>
<span class="n">cv2_imshow</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">get_image</span><span class="p">()[:,:,::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../assets/javascripts/workers/search.fb4a9340.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.ca5457b8.min.js"></script>
      
    
  </body>
</html>